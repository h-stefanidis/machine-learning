{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4bbd726-78b3-4c9f-8b41-734b82d26d97",
   "metadata": {},
   "source": [
    "# COS80027 Machine Learning\n",
    "## Assignment 1, 2025, Semester 1\n",
    "## Student Details:\n",
    "* Name: Harrison Stefanidis\n",
    "* Student ID: 105260443\n",
    "* Email: 105260443@student.swin.edu.au\n",
    "* Submission Date: 20/04/2025\n",
    "* TuteLab Class: Friday 2:30pm-4:30pm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf80ee2-792a-4f8f-b00b-4e3460ecad25",
   "metadata": {},
   "source": [
    "## Task 1 - Data Loading and Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8793051d-4721-45d5-ad75-58bb6782352b",
   "metadata": {},
   "source": [
    "### Sub-Task 1.1 - Import Files and Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "900fcf2b-ad87-4464-a14b-0ef0bd407e10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape: (2400, 3)\n",
      "columns: ['website_name', 'text', 'is_positive_sentiment']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>website_name</th>\n",
       "      <th>text</th>\n",
       "      <th>is_positive_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>amazon</td>\n",
       "      <td>Oh and I forgot to also mention the weird colo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>amazon</td>\n",
       "      <td>THAT one didn't work either.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>amazon</td>\n",
       "      <td>Waste of 13 bucks.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>amazon</td>\n",
       "      <td>Product is useless, since it does not have eno...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>amazon</td>\n",
       "      <td>None of the three sizes they sent with the hea...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  website_name                                               text  \\\n",
       "0       amazon  Oh and I forgot to also mention the weird colo...   \n",
       "1       amazon                       THAT one didn't work either.   \n",
       "2       amazon                                 Waste of 13 bucks.   \n",
       "3       amazon  Product is useless, since it does not have eno...   \n",
       "4       amazon  None of the three sizes they sent with the hea...   \n",
       "\n",
       "   is_positive_sentiment  \n",
       "0                      0  \n",
       "1                      0  \n",
       "2                      0  \n",
       "3                      0  \n",
       "4                      0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load without headers and assign correct column names\n",
    "x_train = pd.read_csv('x_train.csv', header=None, names=['website_name','text'])\n",
    "y_train = pd.read_csv('y_train.csv', header=None, names=['is_positive_sentiment'])\n",
    "x_test  = pd.read_csv('x_test.csv', header=None, names=['website_name','text'])\n",
    "\n",
    "# Merge train inputs & labels\n",
    "train = x_train.merge(y_train, left_index=True, right_index=True)\n",
    "\n",
    "# Quick check for shapes and columns\n",
    "print(\"train shape:\", train.shape)\n",
    "print(\"columns:\", train.columns.tolist())\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aef48624-9fbf-482a-bf0c-7f9a2fea2167",
   "metadata": {},
   "source": [
    "### Sub-Task 1.2 - Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f3f76862-8421-4c55-96ca-856275a71684",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive ratio: 0.5\n",
      "\n",
      "Sample raw reviews:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>website_name</th>\n",
       "      <th>text</th>\n",
       "      <th>is_positive_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2240</th>\n",
       "      <td>yelp</td>\n",
       "      <td>The service was outshining &amp;amp; I definitely ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1249</th>\n",
       "      <td>imdb</td>\n",
       "      <td>If there was ever a movie that needed word-of-...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1761</th>\n",
       "      <td>yelp</td>\n",
       "      <td>Worst food/service I've had in a while.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>857</th>\n",
       "      <td>imdb</td>\n",
       "      <td>Now this is a movie I really dislike.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1263</th>\n",
       "      <td>imdb</td>\n",
       "      <td>That was nice.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     website_name                                               text  \\\n",
       "2240         yelp  The service was outshining &amp; I definitely ...   \n",
       "1249         imdb  If there was ever a movie that needed word-of-...   \n",
       "1761         yelp            Worst food/service I've had in a while.   \n",
       "857          imdb            Now this is a movie I really dislike.     \n",
       "1263         imdb                                   That was nice.     \n",
       "\n",
       "      is_positive_sentiment  \n",
       "2240                      1  \n",
       "1249                      1  \n",
       "1761                      0  \n",
       "857                       0  \n",
       "1263                      1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Investigate class balance and provide examples\n",
    "print(\"Positive ratio:\", train['is_positive_sentiment'].mean())\n",
    "print(\"\\nSample raw reviews:\")\n",
    "display(train[['website_name', 'text', 'is_positive_sentiment']].sample(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52115046-704c-4181-82e0-ea706b8e6b83",
   "metadata": {},
   "source": [
    "### Sub-Task 1.3 - Cleaning the Data/Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bfc995f2-1555-417d-bd94-fbf527ee0716",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIG: Not my thing.\n",
      "CLEAN: last time buying from you \n",
      "\n",
      "ORIG: The service was terrible, food was mediocre.\n",
      "CLEAN: i dont think well be going back anytime soon \n",
      "\n",
      "ORIG: Battery life still not long enough in Motorola Razor V3i.\n",
      "CLEAN: i wouldnt recommend buying this product \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re, string\n",
    "\n",
    "# Create a cleaning function for data\n",
    "def clean_text(s):\n",
    "    # Remove punctuation\n",
    "    s = s.translate(str.maketrans('', '', string.punctuation))\n",
    "    # Force lowercase\n",
    "    s = s.lower()\n",
    "    # Remove whitespace\n",
    "    s = re.sub(r'\\s+', ' ', s).strip()\n",
    "    return s\n",
    "\n",
    "# Apply to both train and test data\n",
    "train['clean_text'] = train ['text'].apply(clean_text)\n",
    "x_test['clean_text'] = x_test['text'].apply(clean_text)\n",
    "\n",
    "# Show results on a sample, original vs clean\n",
    "for orig, clean in zip(train['text'].sample(3), train['clean_text'].sample(3)):\n",
    "    print(\"ORIG:\", orig)\n",
    "    print(\"CLEAN:\", clean, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa40344a-a6aa-4e40-bd90-e1a142a7e0cc",
   "metadata": {},
   "source": [
    "## Task 2 - Feature Representation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0625ade2-2429-49c9-a61d-17d856ac1075",
   "metadata": {},
   "source": [
    "### Task 2.1 - BoW Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "693b47ae-a73f-41bd-93aa-fcf21a284f7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size: 1164\n",
      "X shape: (2400, 1164) X_test shape: (600, 1164)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Build a CountVectorizer\n",
    "vectorizer = CountVectorizer(\n",
    "    ngram_range=(1,2), # Unigrams + bigrams\n",
    "    min_df=5,          # Ignore very rare\n",
    "    max_df=0.8,        # Ignore very common\n",
    "    binary=False       # Use counts; set as True for presence/absence\n",
    ")\n",
    "\n",
    "# Fit on ALL training clean text\n",
    "vectorizer.fit(train['clean_text'])\n",
    "print(\"Vocab size:\", len(vectorizer.vocabulary_))\n",
    "\n",
    "# Transform into feature matrices\n",
    "X = vectorizer.transform(train['clean_text'])\n",
    "X_test = vectorizer.transform(x_test['clean_text'])\n",
    "\n",
    "print(\"X shape:\", X.shape, \"X_test shape:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa8e250-4b14-479a-8ff4-c2e651dab927",
   "metadata": {},
   "source": [
    "## Task 3 - Classification and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6838a1d-71c1-47db-9932-e1116c203db3",
   "metadata": {},
   "source": [
    "### Sub-Task 3.1 - Splitting the Training/Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "360936fb-13f9-4822-856c-e11bdc95f0df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training features shape: (1920, 1164)\n",
      "Validation features shape: (480, 1164)\n",
      "Training labels shape: (1920,)\n",
      "Validation labels shape: (480,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Identified y as target array containing 0-1 labels\n",
    "y = train['is_positive_sentiment'].values\n",
    "\n",
    "# Split X and y into training and validation sets\n",
    "X_train, X_val, y_train_split, y_val = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,   # 20% of data for validation\n",
    "    random_state=42, # Reproducible split\n",
    "    stratify=y       # Preserve class balance in both sets\n",
    ")\n",
    "\n",
    "# Print shapes to confirm split\n",
    "print(\"Training features shape:\", X_train.shape)\n",
    "print(\"Validation features shape:\", X_val.shape)\n",
    "print(\"Training labels shape:\", y_train_split.shape)\n",
    "print(\"Validation labels shape:\", y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a01d517c-0bc3-4e19-9111-37f39886aaa5",
   "metadata": {},
   "source": [
    "### Sub-Task 3.2 - Hyperparameter Search and Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1c9813eb-4840-4729-9952-4ea8f3f71140",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n",
      "Best regularisation C: 1.0\n",
      "Best cross-val accuracy: 0.7817708333333334\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Pipeline that contains only the classifier\n",
    "pipe = Pipeline([\n",
    "    ('clf', LogisticRegression(max_iter=1000, solver='liblinear'))\n",
    "])\n",
    "\n",
    "# Define hyperparameter grid\n",
    "param_grid = {\n",
    "    'clf__C': [0.1, 1.0, 10.0] # C is the inverse regularisation strength in logistic regression\n",
    "}\n",
    "\n",
    "# 3-fold cross-validation grid to search for optimal accuracy\n",
    "grid = GridSearchCV(\n",
    "    pipe,\n",
    "    param_grid,\n",
    "    cv=3,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1, # Use all CPUs\n",
    "    verbose=1  # Print progress\n",
    ")\n",
    "\n",
    "# Run grid search on the train split\n",
    "grid.fit(X_train, y_train_split)\n",
    "\n",
    "# Output the best hyperparameter and correpsonding CV accuracy\n",
    "print(\"Best regularisation C:\", grid.best_params_['clf__C'])\n",
    "print(\"Best cross-val accuracy:\", grid.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb4904d-1e0b-4b97-ae0a-afec5082c08a",
   "metadata": {},
   "source": [
    "### Sub-Task 3.3 - Validation Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "91580178-fa5e-49a7-bf57-94716eb1be74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Classification Report ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82       240\n",
      "           1       0.82      0.80      0.81       240\n",
      "\n",
      "    accuracy                           0.81       480\n",
      "   macro avg       0.81      0.81      0.81       480\n",
      "weighted avg       0.81      0.81      0.81       480\n",
      "\n",
      "=== Confusion Matrix ===\n",
      "[[198  42]\n",
      " [ 47 193]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Retrieve best estimator from grid search\n",
    "best_clf = grid.best_estimator_\n",
    "\n",
    "# Generate predictions on the hold-out validation set\n",
    "y_pred = best_clf.predict(X_val)\n",
    "\n",
    "# Detailed classification metrics\n",
    "print(\"=== Classification Report ===\")\n",
    "print(classification_report(y_val, y_pred))\n",
    "\n",
    "# Confusion matrix\n",
    "print(\"=== Confusion Matrix ===\")\n",
    "print(confusion_matrix(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaffb786-4ea5-409f-9f19-0b1d884531ac",
   "metadata": {},
   "source": [
    "### Sub-Task 3.4 - Final Model and Test Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8fc1411e-94cd-441f-949b-4d7d5a03cb95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportion of test reviews predicted positive: 0.43\n"
     ]
    }
   ],
   "source": [
    "# Retrain final logistic regression on the full training data\n",
    "final_clf = LogisticRegression(\n",
    "    C=grid.best_params_['clf__C'],\n",
    "    max_iter=1000,\n",
    "    solver='liblinear'\n",
    ")\n",
    "final_clf.fit(X, y) # X and y are all training examples\n",
    "\n",
    "# Predict sentiments for the test set\n",
    "test_preds = final_clf.predict(X_test)\n",
    "\n",
    "# Compute and display proportion of reviews predicted positive\n",
    "positive_ratio = test_preds.mean()\n",
    "print(\"Proportion of test reviews predicted positive:\", positive_ratio)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
